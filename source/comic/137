pg===
137
title===
ethicsbot
content===
<img src="/comics/qxlkbh137.png"
  title="Everything I say is a li... That doesn't work with these, does it?" />
extra===
For those who aren't aware, a "jailbreak" is what you call it when someone gets around ethical restrictions that chatbots are supposed to have via some clever methods. They've gained some notoriety recently because ChatGPT and similar language models have ethical restrictions that are supposed to limit their output, but lots of people find ways to get around these restrictions and get it to do things it's not supposed to-- for a tame example, getting it to endorse jaywalking or something like that. There are lots of examples all across the internet, especially on social media.<br>
<br>
To my knowledge (I being musija), not many works of fiction have done much about jailbreaks, yet, since the idea is fairly new.

nav===
default
tags===
qxlkbh
date===
20230510
